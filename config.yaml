# config.yaml - User Configuration (Overrides defaults in config.py)

output:
  directory: output  # Relative to project root
  scraped_jobs_file: scraped_jobs.json
  analysis_output_file: analysis_results.json
  debug_output_file: debug_info.json

# --- LLM Configuration ---
# Select the provider to use: "openai", "ollama", or "gemini"
llm_provider: "openai" # Defaulting to openai (for LM Studio)

openai: # Settings for OpenAI-compatible APIs (LM Studio, etc.)
  # For LM Studio, typically http://localhost:1234/v1
  base_url: http://localhost:1234/v1
  # Model identifier depends on the model loaded in LM Studio.
  # Check LM Studio server logs or UI for the exact model ID.
  model: "codellama-34b-python" # Example model identifier
  api_key: "lm-studio" # Placeholder, often not needed for local LM Studio
  request_timeout: 900    # Timeout in seconds for API calls
  max_retries: 0          # Max number of retries on failure
  retry_delay: 5          # Initial delay in seconds before first retry (exponential backoff)

ollama: # Settings for local Ollama server
  base_url: http://localhost:11434 # Default Ollama URL
  # Model name as pulled/available in Ollama (e.g., "llama3:instruct")
  model: "codellama-34b-python"
  request_timeout: 900
  max_retries: 2
  retry_delay: 5

gemini: # Settings for Google Gemini API (via AI Studio)
  # Model name (e.g., "gemini-1.5-flash-latest", "gemini-1.5-pro-latest")
  #model: "gemini-1.5-flash-latest"
  model: "learnlm-2.0-flash-experimental"
  # IMPORTANT: Obtain your API key from Google AI Studio and set it here or via environment variable GOOGLE_API_KEY
  api_key: "AIzaSyADjg4kO3d1q-Nwy6qzX_FV6GCeKXLSSjw" # Replace with your actual key
  # Note: Timeout, retries might be handled differently by the google-generativeai client library itself.
  # These values might be used for custom retry logic if needed, but check library defaults first.
  request_timeout: 900
  max_retries: 0
  retry_delay: 5

# --- Analysis Settings ---
analysis:
  prompts_dir: analysis/prompts
  resume_prompt_file: resume_extraction.prompt
  suitability_prompt_file: suitability_analysis.prompt
  job_extraction_prompt_file: job_extraction.prompt
  max_prompt_chars: 16739 # Max chars for a single prompt (API limit)
  log_full_prompt: true # Added to enable verbose prompt logging

scraping:
  default_sites: ["linkedin"]
  default_results_limit: 10
  default_days_old: 14  # Use days, not hours
  default_country_indeed: "usa"
  linkedin_fetch_description: True
  linkedin_company_ids: []

geocoding:
  geopy_user_agent: "MyJobSpyAI/1.0 (kasnycdev@gmail.com)" # Update with your email

logging:
  level: DEBUG
  format: "%(message)s"
  date_format: "[%X]"

# --- Pytrail Configuration ---
# Configuration for pytrail interactive debugger
pytrail:
  enabled: true # Set to false to disable pytrail
  color_output: true # Enable/disable color output
  keybindings: # Customize keybindings (refer to pytrail documentation for options)
    debug_menu: "f1" # Example: Use F1 to open the debug menu
    continue: "c"
    next: "n"
    step_in: "s"
    step_out: "o"
    quit: "q"
  debug_menu: # Settings for the debug menu
    enabled: true # Enable/disable the debug menu
    # Add other debug menu specific options here if available in pytrail docs
